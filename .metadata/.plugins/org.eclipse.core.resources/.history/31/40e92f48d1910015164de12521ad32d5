package com.cnkvha.uuol.cache.server.handlers.request.general;

import java.io.ByteArrayInputStream;
import java.sql.Blob;
import java.sql.Connection;
import java.sql.PreparedStatement;
import java.sql.ResultSet;
import java.sql.SQLException;
import java.sql.Statement;
import java.util.UUID;

import com.cnkvha.uuol.cache.protocol.UUOLComponent;
import com.cnkvha.uuol.cache.protocol.data.planet.ChunkData;
import com.cnkvha.uuol.cache.protocol.handlers.RequestHandler;
import com.cnkvha.uuol.cache.protocol.message.general.request.CacheRequestLoadChunk;
import com.cnkvha.uuol.cache.protocol.message.general.response.CacheResponseLoadChunk;
import com.cnkvha.uuol.cache.server.CacheServer;
import com.cnkvha.uuol.cache.server.cache.planet.PlanetChunkCache;
import com.cnkvha.uuol.cache.server.generator.PlanetGenerator;
import com.cnkvha.uuol.cache.server.generator.PlanetGeneratorManager;
import com.cnkvha.uuol.sjl.ConnectionPool;
import com.cnkvha.uuol.sjl.SerializationTool;
import com.cnkvha.uuol.sjl.math.Vector3Long;

public class RequestHandlerLoadChunk extends
		RequestHandler<CacheRequestLoadChunk, CacheResponseLoadChunk> {

	public final static RequestHandlerLoadChunk STATIC_INSTANCE = new RequestHandlerLoadChunk();
	
	 /* [CHUNK LOAD PROCESS]
	 * 1. Disable AUTO_COMMIT
	 * 2. DO: SELECT `SerializedData` FROM `chunks` WHERE ... FOR UPDATE
	 * 3. Not null, already generated and continue steps. Else, go to step [6]
	 * 4. Check that cluster is online or not, if not, update to ourself and load the data. 
	 * 5. Do 'COMMIT' and exit process
	 * 6. Generate an chunk
	 * 7. DO: INSERT ...
	 * 8. If step 7 returns errors <No.1062, State=23000>, it means others inserted first, commit and quit.
	 * 9. Generate the chunk and cache it.  
	 */
	

	@Override
	public CacheResponseLoadChunk handle(CacheRequestLoadChunk req) {
		CacheResponseLoadChunk response = new CacheResponseLoadChunk();
		response.reqid = req.reqid;
		
		final String thisServer = CacheServer.getInstance().getGms().getInstanceName();
		final UUID cPlanet = req.planet;
		final Vector3Long cPos = req.chunkLocation;
		
		//Detect if already loaded
		{
			PlanetChunkCache planet = CacheServer.getInstance().getCache().getPlanet(cPlanet);
			if(planet != null){
				if(planet.isChunkCached(cPos)){
					response.reqid = req.reqid;
					response.status = CacheResponseLoadChunk.STATUS_ALREADY_LOADED;
					return response;
				}
			}
		}
		
		CacheServer.getInstance().getLogger().info("==> Continuing process... ");

		Connection conn = ConnectionPool.getConnection();
		if (conn == null) {
			response.status = CacheResponseLoadChunk.FAILD_LOAD;
			return response;
		}
		
		//[STEP 1]
		boolean savedAutoCommit = true;
		try {
			savedAutoCommit = conn.getAutoCommit();
			conn.setAutoCommit(false);
		} catch (SQLException e) {
			response.status = CacheResponseLoadChunk.FAILD_LOAD;
			return response;
		}
		final boolean finalSavedAutoCommit = savedAutoCommit;

		CacheServer.getInstance().getThreadPool().execute(new Runnable() {
			@Override
			public void run() {
				Statement stm = null;
				boolean gotError = false;
				try {
					stm = conn.createStatement();
					stm.execute("BEGIN WORK");	//Start our job baby. 
					//[STEP 2]
					{
						ResultSet rs = stm.executeQuery("SELECT `SerializedData`,`CacheServer` FROM `chunks` WHERE " +
										"(`PlanetID_Most`,`PlanetID_Least`)=(" + cPlanet.getMostSignificantBits() + "," + cPlanet.getLeastSignificantBits() + ") AND " + 
										"(`ChunkX`,`ChunkY`,`ChunkZ`)=" + String.format("(%s,%s,%s)", cPos.x, cPos.y, cPos.z)
										//+ " LOCK IN SHARE MODE" //Locks its ass
									);
						/**
						 * 0=cached
						 * 1=need cache
						 * 2=not exist
						 */
						int stat = -1;
						ChunkData chunk = null;
						String clusterInRecord = null;
						if(rs.next()){
							//We got the thing, check wether a cluster already cached it. 
							clusterInRecord = rs.getString("CacheServer");
							if(clusterInRecord.equals("") || clusterInRecord.trim().equals("") || !CacheServer.getInstance().getClientHandler().getCurrentClusters().contains(clusterInRecord)){
								//target is fucking down, dude
								//we re-cache it
								stat = 1;
								//read the shit
								Blob blob = rs.getBlob("SerializedData");
								byte[] bin = blob.getBytes(1, (int) blob.length());
								chunk = (ChunkData) SerializationTool.decode(bin, 4096000);
							}else{
								stat = 0;
							}
						}else{
							//Cool, this is a non-exist chunk.
							stat = 2;
						}
						rs.close();
						//Process the status number
						if(stat == 0){
							//[STEP 4] - Already loaded by other people
							CacheServer.getInstance().getLogger().info("==> " + cPos.toString() + " is loaded by other people!? ");
							response.status = CacheResponseLoadChunk.LOADED_BY_OTHER;
							CacheServer.getInstance().sendPacket(response, UUOLComponent.GENERAL);
							return;
						}
						if(stat == 1){
							//[STEP 4] - Not loaded
							stm.executeUpdate("UPDATE `chunks` SET `CacheServer`='" + thisServer + "' WHERE (`PlanetID_Most`,`PlanetID_Least`)="
							+ String.format("(%s,%s)", cPlanet.getMostSignificantBits(), cPlanet.getLeastSignificantBits()) + " AND "
							+ "(`ChunkX`,`ChunkY`,`ChunkZ`)=" + String.format("(%s,%s,%s)", cPos.x, cPos.y, cPos.z) + " AND "
							+ "`CacheServer`='" + (clusterInRecord != null ? clusterInRecord : "") + "'");
							
							//Cache it
							PlanetChunkCache planet = CacheServer.getInstance().getCache().initialPlanetCache(cPlanet, null);
							planet.cacheChunk(cPos, chunk);
							
							response.status = CacheResponseLoadChunk.STATUS_LOADED;
							CacheServer.getInstance().sendPacket(response, UUOLComponent.GENERAL);
							return;
						}
						if(stat == 2){
							//[STEP 6]
							stm.execute("COMMIT WORK");	//Unlock?
							stm.execute("SET AUTOCOMMIT=1");
							int updated = 0;
							try{
								updated = stm.executeUpdate("INSERT INTO `chunks` (`PlanetID_Most`,`PlanetID_Least`,`ChunkX`,`ChunkY`,`ChunkZ`,`SerializedData`,`CacheServer`) VALUES (" + 
										cPlanet.getMostSignificantBits() + "," + cPlanet.getLeastSignificantBits() + "," + String.format("%s,%s,%s", cPos.x, cPos.y, cPos.z) + ",0x00,'" + thisServer + "')");
							}catch(SQLException e){
								if(e.getErrorCode() == 1062 && e.getSQLState().equals("23000")){
									CacheServer.getInstance().getLogger().info("==> " + cPos.toString() + " pos is already inserted! ");
									//Another server is already inserted before us.
									response.status = CacheResponseLoadChunk.LOADED_BY_OTHER;
									CacheServer.getInstance().sendPacket(response, UUOLComponent.GENERAL);
									return;
								}else{
									throw e;	//Return the error back
								}
							}
							stm.execute("SET AUTOCOMMIT=" + (finalSavedAutoCommit ? "1" : "0"));
							if(updated <= 0){
								//Inserted nothing? Shit! ERROR!  
								throw new Exception("Insert data faild! ");
							}
							PlanetChunkCache planet = CacheServer.getInstance().getCache().initialPlanetCache(cPlanet, null);
							if(planet == null){
								throw new Exception("Initialization of planet chunk cache faild! ");
							}
							PlanetGenerator generator = PlanetGeneratorManager.get(planet.getGenerator());
							if(generator == null){
								throw new Exception("Undefined planet generator! ");
							}
							ChunkData newChunk = generator.generate(planet.getSeed(), cPos.x, cPos.y, cPos.z);
							planet.cacheChunk(cPos, newChunk);
							{
								PreparedStatement updStm = conn.prepareStatement("UPDATE `chunks` SET `SerializedData`=? WHERE (`PlanetID_Most`,`PlanetID_Least`,`ChunkX`,`ChunkY`,`ChunkZ`)=(?,?,?,?,?)");
								byte[] newChunkBin = SerializationTool.encode(newChunk);
								updStm.setBlob(1, new ByteArrayInputStream(newChunkBin));
								updStm.setLong(2, cPlanet.getMostSignificantBits());
								updStm.setLong(3, cPlanet.getLeastSignificantBits());
								updStm.setLong(4, cPos.x);
								updStm.setLong(5, cPos.y);
								updStm.setLong(6, cPos.z);
								updated = updStm.executeUpdate();
								if(updated <= 0){
									//SHIT! 
									throw new Exception("Faild to save generated chunk to the database! ");
								}
								updStm.close();
							}
							response.status = CacheResponseLoadChunk.STATUS_LOADED;
							CacheServer.getInstance().sendPacket(response, UUOLComponent.GENERAL);
							return;
						}
					}
				} catch (Exception e) {
					gotError = true;
					CacheServer
							.getInstance()
							.getLogger()
							.error("Error loading chunk "
									+ req.chunkLocation.toString()
									+ ", message: " + e.getMessage());
					e.printStackTrace();
					response.status = CacheResponseLoadChunk.FAILD_LOAD;
					CacheServer.getInstance().sendPacket(response,
							UUOLComponent.GENERAL);
				} finally {
					try {
						if (stm != null && !stm.isClosed()) {
							if (gotError)
								stm.execute("ROLLBACK");
							stm.execute("COMMIT WORK"); // Done the job
							stm.close();
						}
					} catch (Exception e) {}
					if (conn != null) {
						try {
							conn.setAutoCommit(finalSavedAutoCommit);
						} catch (Exception e) {}
						try {
							conn.close();
						} catch (Exception e) {}
					}
				}
			}
		});
		return null; // Return later
	}

}
